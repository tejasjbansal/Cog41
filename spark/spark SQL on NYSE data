Spark-SQL
---------



case class nyse(exchangename:String, stockid:String, dt:String, open:Double, high:Double, low:Double, close:Double, volume:Long, adj_close:Double) ; 

val nyseRDD = sc.textFile("file:/home/cloudera/NYSE.csv")


val nyseArray = nyseRDD.map(a =>a.split(","))

val nyseObjRDD = nyseArray.map(v => nyse(v(0).trim, v(1).trim, v(2), v(3).toDouble, v(4).toDouble,v(5).toDouble, v(6).toDouble, v(7).toLong, v(8).toDouble))

val nyseDF = nyseObjRDD.toDF

nyseDF.printSchema

nyseDF.show

nyseDF.registerTempTable("sp_nyse");

to find total volume for Top 10 stocks
-----------------------------------
val top10 = spark.sql("select stockid, sum(volume) as total from sp_nyse group by stockid order by total desc LIMIT 10")

top10.show


find max volume on a particular day for each stock
--------------------------------------------------
val maxVol = spark.sql("select sp_nyse.stockid, dt, volume from sp_nyse join (select stockid, max(volume) as maxvol from sp_nyse group by stockid) abc on (sp_nyse.stockid=abc.stockid and sp_nyse.volume = abc.maxvol) order by sp_nyse.stockid")




sending the output to hive table
--------------------------------
top10.write.mode("overwrite").saveAsTable("training.top10");



top10.show()
top10.printSchema()

//this command is applicable in 2.x Spark
top10.write.csv("/home/training/sparksql1");






to find the max variance for each stock (order it on max variance. show top 10 records)
---------------------------------------------------------------------------------------

val top10var = spark.sql("select stockid, round(max((high-low)/low*100),2) as maxvar from sp_nyse group by stockid order by maxvar desc LIMIT 10")

//top10var.write.csv("hdfs://localhost:54310/sparksql2");

top10var.collect.foreach(println)


val sp_nyse1 = spark.sql("select sp_nyse.stockid, dt, round((high-low)/low*100,2)  as mxvar  from sp_nyse")

sp_nyse1.registerTempTable("sp_nyse1")


val top10varWithdt = spark.sql("select sp_nyse1.stockid, dt, mxvar  from sp_nyse1 join (select sp_nyse.stockid, round(max((high-low)/low*100),2) as maxvar from sp_nyse group by sp_nyse.stockid) abc on sp_nyse1.stockid = abc.stockid and sp_nyse1.mxvar = abc.maxvar order by sp_nyse1.mxvar desc limit 10")

sending the results to hive table
--------------------------------
top10var.write.mode("overwrite").saveAsTable("cognizant.top10var");
 

to find the highest price for each stock
----------------------------------------
val highprice = spark.sql("select stockid, round(max(high),2) as high from sp_nyse group by stockid order by stockid")


to find the lowest price for each stock
----------------------------------------
val lowprice = spark.sql("select stockid, round(min(low),2) as low from sp_nyse group by stockid order by stockid")


custs.txt ---- customer(custno:Int, fname:String, lname:String, age:Int, profession:String)
txns1.txt ----- sales(txnid:String, dt:String, custno:Int, amt:Double, category:String, product:String, city:String,
                       state:String, spendby:String) 

top 10 customers with their name
top 10 products
top 10 cities








